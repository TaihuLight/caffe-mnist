I0524 09:46:17.234647  5984 caffe.cpp:211] Use CPU.
I0524 09:46:17.235647  5984 solver.cpp:48] Initializing solver from parameters: 
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "../../../examples/mnist/lenet"
solver_mode: CPU
net: "../../../examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
I0524 09:46:17.259663  5984 solver.cpp:91] Creating training net from net file: ../../../examples/mnist/lenet_train_test.prototxt
I0524 09:46:17.260664  5984 net.cpp:332] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0524 09:46:17.260664  5984 net.cpp:332] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0524 09:46:17.260664  5984 net.cpp:58] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "../../../examples/mnist/Deal_Data/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "HingeLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I0524 09:46:17.260664  5984 layer_factory.hpp:77] Creating layer mnist
I0524 09:46:17.260664  5984 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0524 09:46:17.260664  5984 net.cpp:100] Creating Layer mnist
I0524 09:46:17.260664  5984 net.cpp:418] mnist -> data
I0524 09:46:17.260664  5984 net.cpp:418] mnist -> label
I0524 09:46:17.260664 16736 db_lmdb.cpp:40] Opened lmdb ../../../examples/mnist/Deal_Data/mnist_train_lmdb
I0524 09:46:17.261665  5984 data_layer.cpp:41] output data size: 64,1,28,28
I0524 09:46:17.261665  5984 net.cpp:150] Setting up mnist
I0524 09:46:17.261665  5984 net.cpp:157] Top shape: 64 1 28 28 (50176)
I0524 09:46:17.261665  5984 net.cpp:157] Top shape: 64 (64)
I0524 09:46:17.261665  5984 net.cpp:165] Memory required for data: 200960
I0524 09:46:17.261665  5984 layer_factory.hpp:77] Creating layer conv1
I0524 09:46:17.261665  5984 net.cpp:100] Creating Layer conv1
I0524 09:46:17.261665  5984 net.cpp:444] conv1 <- data
I0524 09:46:17.261665  5984 net.cpp:418] conv1 -> conv1
I0524 09:46:17.261665  5984 net.cpp:150] Setting up conv1
I0524 09:46:17.261665  5984 net.cpp:157] Top shape: 64 20 24 24 (737280)
I0524 09:46:17.261665  5984 net.cpp:165] Memory required for data: 3150080
I0524 09:46:17.261665  5984 layer_factory.hpp:77] Creating layer pool1
I0524 09:46:17.261665  5984 net.cpp:100] Creating Layer pool1
I0524 09:46:17.261665  5984 net.cpp:444] pool1 <- conv1
I0524 09:46:17.261665  5984 net.cpp:418] pool1 -> pool1
I0524 09:46:17.261665  5984 net.cpp:150] Setting up pool1
I0524 09:46:17.261665  5984 net.cpp:157] Top shape: 64 20 12 12 (184320)
I0524 09:46:17.261665  5984 net.cpp:165] Memory required for data: 3887360
I0524 09:46:17.261665  5984 layer_factory.hpp:77] Creating layer conv2
I0524 09:46:17.262665  5984 net.cpp:100] Creating Layer conv2
I0524 09:46:17.262665  5984 net.cpp:444] conv2 <- pool1
I0524 09:46:17.262665  5984 net.cpp:418] conv2 -> conv2
I0524 09:46:17.262665  5984 net.cpp:150] Setting up conv2
I0524 09:46:17.262665  5984 net.cpp:157] Top shape: 64 50 8 8 (204800)
I0524 09:46:17.262665  5984 net.cpp:165] Memory required for data: 4706560
I0524 09:46:17.262665  5984 layer_factory.hpp:77] Creating layer pool2
I0524 09:46:17.262665  5984 net.cpp:100] Creating Layer pool2
I0524 09:46:17.262665  5984 net.cpp:444] pool2 <- conv2
I0524 09:46:17.262665  5984 net.cpp:418] pool2 -> pool2
I0524 09:46:17.262665  5984 net.cpp:150] Setting up pool2
I0524 09:46:17.262665  5984 net.cpp:157] Top shape: 64 50 4 4 (51200)
I0524 09:46:17.262665  5984 net.cpp:165] Memory required for data: 4911360
I0524 09:46:17.262665  5984 layer_factory.hpp:77] Creating layer ip1
I0524 09:46:17.262665  5984 net.cpp:100] Creating Layer ip1
I0524 09:46:17.262665  5984 net.cpp:444] ip1 <- pool2
I0524 09:46:17.262665  5984 net.cpp:418] ip1 -> ip1
I0524 09:46:17.266669  5984 net.cpp:150] Setting up ip1
I0524 09:46:17.266669  5984 net.cpp:157] Top shape: 64 500 (32000)
I0524 09:46:17.266669  5984 net.cpp:165] Memory required for data: 5039360
I0524 09:46:17.266669  5984 layer_factory.hpp:77] Creating layer relu1
I0524 09:46:17.266669  5984 net.cpp:100] Creating Layer relu1
I0524 09:46:17.266669  5984 net.cpp:444] relu1 <- ip1
I0524 09:46:17.266669  5984 net.cpp:405] relu1 -> ip1 (in-place)
I0524 09:46:17.266669  5984 net.cpp:150] Setting up relu1
I0524 09:46:17.266669  5984 net.cpp:157] Top shape: 64 500 (32000)
I0524 09:46:17.266669  5984 net.cpp:165] Memory required for data: 5167360
I0524 09:46:17.266669  5984 layer_factory.hpp:77] Creating layer ip2
I0524 09:46:17.266669  5984 net.cpp:100] Creating Layer ip2
I0524 09:46:17.266669  5984 net.cpp:444] ip2 <- ip1
I0524 09:46:17.266669  5984 net.cpp:418] ip2 -> ip2
I0524 09:46:17.266669  5984 net.cpp:150] Setting up ip2
I0524 09:46:17.266669  5984 net.cpp:157] Top shape: 64 10 (640)
I0524 09:46:17.266669  5984 net.cpp:165] Memory required for data: 5169920
I0524 09:46:17.266669  5984 layer_factory.hpp:77] Creating layer loss
I0524 09:46:17.266669  5984 net.cpp:100] Creating Layer loss
I0524 09:46:17.266669  5984 net.cpp:444] loss <- ip2
I0524 09:46:17.266669  5984 net.cpp:444] loss <- label
I0524 09:46:17.266669  5984 net.cpp:418] loss -> loss
I0524 09:46:17.266669  5984 net.cpp:150] Setting up loss
I0524 09:46:17.266669  5984 net.cpp:157] Top shape: (1)
I0524 09:46:17.266669  5984 net.cpp:160]     with loss weight 1
I0524 09:46:17.266669  5984 net.cpp:165] Memory required for data: 5169924
I0524 09:46:17.266669  5984 net.cpp:226] loss needs backward computation.
I0524 09:46:17.266669  5984 net.cpp:226] ip2 needs backward computation.
I0524 09:46:17.266669  5984 net.cpp:226] relu1 needs backward computation.
I0524 09:46:17.266669  5984 net.cpp:226] ip1 needs backward computation.
I0524 09:46:17.266669  5984 net.cpp:226] pool2 needs backward computation.
I0524 09:46:17.266669  5984 net.cpp:226] conv2 needs backward computation.
I0524 09:46:17.266669  5984 net.cpp:226] pool1 needs backward computation.
I0524 09:46:17.266669  5984 net.cpp:226] conv1 needs backward computation.
I0524 09:46:17.266669  5984 net.cpp:228] mnist does not need backward computation.
I0524 09:46:17.266669  5984 net.cpp:270] This network produces output loss
I0524 09:46:17.266669  5984 net.cpp:283] Network initialization done.
I0524 09:46:17.266669  5984 solver.cpp:60] Solver scaffolding done.
I0524 09:46:17.267669  5984 caffe.cpp:252] Starting Optimization
I0524 09:46:17.267669  5984 solver.cpp:279] Solving LeNet
I0524 09:46:17.267669  5984 solver.cpp:280] Learning Rate Policy: inv
I0524 09:46:17.319702  5984 solver.cpp:228] Iteration 0, loss = 9.80482
I0524 09:46:17.319702  5984 solver.cpp:244]     Train net output #0: loss = 9.80482 (* 1 = 9.80482 loss)
I0524 09:46:17.319702  5984 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0524 09:46:22.348055  5984 solver.cpp:228] Iteration 100, loss = 0.335952
I0524 09:46:22.348055  5984 solver.cpp:244]     Train net output #0: loss = 0.335952 (* 1 = 0.335952 loss)
I0524 09:46:22.348055  5984 sgd_solver.cpp:106] Iteration 100, lr = 0.00992565
I0524 09:46:27.299356  5984 solver.cpp:228] Iteration 200, loss = 0.251291
I0524 09:46:27.299356  5984 solver.cpp:244]     Train net output #0: loss = 0.251291 (* 1 = 0.251291 loss)
I0524 09:46:27.299356  5984 sgd_solver.cpp:106] Iteration 200, lr = 0.00985258
I0524 09:46:32.246332  5984 solver.cpp:228] Iteration 300, loss = 0.211978
I0524 09:46:32.246332  5984 solver.cpp:244]     Train net output #0: loss = 0.211978 (* 1 = 0.211978 loss)
I0524 09:46:32.246332  5984 sgd_solver.cpp:106] Iteration 300, lr = 0.00978075
I0524 09:46:37.203637  5984 solver.cpp:228] Iteration 400, loss = 0.17004
I0524 09:46:37.203637  5984 solver.cpp:244]     Train net output #0: loss = 0.17004 (* 1 = 0.17004 loss)
I0524 09:46:37.203637  5984 sgd_solver.cpp:106] Iteration 400, lr = 0.00971013
I0524 09:46:42.165946  5984 solver.cpp:228] Iteration 500, loss = 0.138747
I0524 09:46:42.165946  5984 solver.cpp:244]     Train net output #0: loss = 0.138747 (* 1 = 0.138747 loss)
I0524 09:46:42.165946  5984 sgd_solver.cpp:106] Iteration 500, lr = 0.00964069
I0524 09:46:47.151269  5984 solver.cpp:228] Iteration 600, loss = 0.183389
I0524 09:46:47.151269  5984 solver.cpp:244]     Train net output #0: loss = 0.183389 (* 1 = 0.183389 loss)
I0524 09:46:47.151269  5984 sgd_solver.cpp:106] Iteration 600, lr = 0.0095724
I0524 09:46:52.121582  5984 solver.cpp:228] Iteration 700, loss = 0.162432
I0524 09:46:52.121582  5984 solver.cpp:244]     Train net output #0: loss = 0.162432 (* 1 = 0.162432 loss)
I0524 09:46:52.121582  5984 sgd_solver.cpp:106] Iteration 700, lr = 0.00950522
I0524 09:46:57.066879  5984 solver.cpp:228] Iteration 800, loss = 0.372279
I0524 09:46:57.066879  5984 solver.cpp:244]     Train net output #0: loss = 0.372279 (* 1 = 0.372279 loss)
I0524 09:46:57.066879  5984 sgd_solver.cpp:106] Iteration 800, lr = 0.00943913
I0524 09:47:01.983156  5984 solver.cpp:228] Iteration 900, loss = 0.190527
I0524 09:47:01.983156  5984 solver.cpp:244]     Train net output #0: loss = 0.190527 (* 1 = 0.190527 loss)
I0524 09:47:01.983156  5984 sgd_solver.cpp:106] Iteration 900, lr = 0.00937411
I0524 09:47:06.926452  5984 solver.cpp:228] Iteration 1000, loss = 0.131944
I0524 09:47:06.926452  5984 solver.cpp:244]     Train net output #0: loss = 0.131944 (* 1 = 0.131944 loss)
I0524 09:47:06.926452  5984 sgd_solver.cpp:106] Iteration 1000, lr = 0.00931012
I0524 09:47:11.824717  5984 solver.cpp:228] Iteration 1100, loss = 2.98023e-008
I0524 09:47:11.824717  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:47:11.824717  5984 sgd_solver.cpp:106] Iteration 1100, lr = 0.00924715
I0524 09:47:16.765012  5984 solver.cpp:228] Iteration 1200, loss = 0.0460658
I0524 09:47:16.765012  5984 solver.cpp:244]     Train net output #0: loss = 0.0460657 (* 1 = 0.0460657 loss)
I0524 09:47:16.765012  5984 sgd_solver.cpp:106] Iteration 1200, lr = 0.00918515
I0524 09:47:21.713310  5984 solver.cpp:228] Iteration 1300, loss = 0.0470133
I0524 09:47:21.713310  5984 solver.cpp:244]     Train net output #0: loss = 0.0470133 (* 1 = 0.0470133 loss)
I0524 09:47:21.713310  5984 sgd_solver.cpp:106] Iteration 1300, lr = 0.00912412
I0524 09:47:26.661609  5984 solver.cpp:228] Iteration 1400, loss = 0.0163891
I0524 09:47:26.661609  5984 solver.cpp:244]     Train net output #0: loss = 0.0163891 (* 1 = 0.0163891 loss)
I0524 09:47:26.661609  5984 sgd_solver.cpp:106] Iteration 1400, lr = 0.00906403
I0524 09:47:31.637926  5984 solver.cpp:228] Iteration 1500, loss = 0.187241
I0524 09:47:31.637926  5984 solver.cpp:244]     Train net output #0: loss = 0.187241 (* 1 = 0.187241 loss)
I0524 09:47:31.637926  5984 sgd_solver.cpp:106] Iteration 1500, lr = 0.00900485
I0524 09:47:36.557206  5984 solver.cpp:228] Iteration 1600, loss = 0.1244
I0524 09:47:36.557206  5984 solver.cpp:244]     Train net output #0: loss = 0.1244 (* 1 = 0.1244 loss)
I0524 09:47:36.557206  5984 sgd_solver.cpp:106] Iteration 1600, lr = 0.00894657
I0524 09:47:41.492496  5984 solver.cpp:228] Iteration 1700, loss = 0.0455163
I0524 09:47:41.492496  5984 solver.cpp:244]     Train net output #0: loss = 0.0455162 (* 1 = 0.0455162 loss)
I0524 09:47:41.492496  5984 sgd_solver.cpp:106] Iteration 1700, lr = 0.00888916
I0524 09:47:46.443796  5984 solver.cpp:228] Iteration 1800, loss = 0.0127532
I0524 09:47:46.443796  5984 solver.cpp:244]     Train net output #0: loss = 0.0127531 (* 1 = 0.0127531 loss)
I0524 09:47:46.443796  5984 sgd_solver.cpp:106] Iteration 1800, lr = 0.0088326
I0524 09:47:51.395098  5984 solver.cpp:228] Iteration 1900, loss = 0.222852
I0524 09:47:51.395098  5984 solver.cpp:244]     Train net output #0: loss = 0.222852 (* 1 = 0.222852 loss)
I0524 09:47:51.395098  5984 sgd_solver.cpp:106] Iteration 1900, lr = 0.00877687
I0524 09:47:56.336391  5984 solver.cpp:228] Iteration 2000, loss = 0.0264189
I0524 09:47:56.336391  5984 solver.cpp:244]     Train net output #0: loss = 0.0264187 (* 1 = 0.0264187 loss)
I0524 09:47:56.336391  5984 sgd_solver.cpp:106] Iteration 2000, lr = 0.00872196
I0524 09:48:01.273684  5984 solver.cpp:228] Iteration 2100, loss = 0.0202505
I0524 09:48:01.274684  5984 solver.cpp:244]     Train net output #0: loss = 0.0202503 (* 1 = 0.0202503 loss)
I0524 09:48:01.274684  5984 sgd_solver.cpp:106] Iteration 2100, lr = 0.00866784
I0524 09:48:06.234990  5984 solver.cpp:228] Iteration 2200, loss = 0.082694
I0524 09:48:06.234990  5984 solver.cpp:244]     Train net output #0: loss = 0.0826938 (* 1 = 0.0826938 loss)
I0524 09:48:06.234990  5984 sgd_solver.cpp:106] Iteration 2200, lr = 0.0086145
I0524 09:48:11.164278  5984 solver.cpp:228] Iteration 2300, loss = 0.150906
I0524 09:48:11.164278  5984 solver.cpp:244]     Train net output #0: loss = 0.150906 (* 1 = 0.150906 loss)
I0524 09:48:11.164278  5984 sgd_solver.cpp:106] Iteration 2300, lr = 0.00856192
I0524 09:48:16.060541  5984 solver.cpp:228] Iteration 2400, loss = 0.0300892
I0524 09:48:16.060541  5984 solver.cpp:244]     Train net output #0: loss = 0.030089 (* 1 = 0.030089 loss)
I0524 09:48:16.060541  5984 sgd_solver.cpp:106] Iteration 2400, lr = 0.00851008
I0524 09:48:20.965812  5984 solver.cpp:228] Iteration 2500, loss = 0.0611875
I0524 09:48:20.965812  5984 solver.cpp:244]     Train net output #0: loss = 0.0611873 (* 1 = 0.0611873 loss)
I0524 09:48:20.965812  5984 sgd_solver.cpp:106] Iteration 2500, lr = 0.00845897
I0524 09:48:25.860074  5984 solver.cpp:228] Iteration 2600, loss = 0.0823044
I0524 09:48:25.861076  5984 solver.cpp:244]     Train net output #0: loss = 0.0823042 (* 1 = 0.0823042 loss)
I0524 09:48:25.861076  5984 sgd_solver.cpp:106] Iteration 2600, lr = 0.00840857
I0524 09:48:30.823384  5984 solver.cpp:228] Iteration 2700, loss = 0.226735
I0524 09:48:30.823384  5984 solver.cpp:244]     Train net output #0: loss = 0.226734 (* 1 = 0.226734 loss)
I0524 09:48:30.823384  5984 sgd_solver.cpp:106] Iteration 2700, lr = 0.00835886
I0524 09:48:35.711642  5984 solver.cpp:228] Iteration 2800, loss = 2.5332e-007
I0524 09:48:35.711642  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:48:35.711642  5984 sgd_solver.cpp:106] Iteration 2800, lr = 0.00830984
I0524 09:48:40.608906  5984 solver.cpp:228] Iteration 2900, loss = 0.0125744
I0524 09:48:40.608906  5984 solver.cpp:244]     Train net output #0: loss = 0.0125742 (* 1 = 0.0125742 loss)
I0524 09:48:40.608906  5984 sgd_solver.cpp:106] Iteration 2900, lr = 0.00826148
I0524 09:48:45.505172  5984 solver.cpp:228] Iteration 3000, loss = 0.0207372
I0524 09:48:45.505172  5984 solver.cpp:244]     Train net output #0: loss = 0.020737 (* 1 = 0.020737 loss)
I0524 09:48:45.505172  5984 sgd_solver.cpp:106] Iteration 3000, lr = 0.00821377
I0524 09:48:50.431046  5984 solver.cpp:228] Iteration 3100, loss = 0.00971297
I0524 09:48:50.431046  5984 solver.cpp:244]     Train net output #0: loss = 0.00971272 (* 1 = 0.00971272 loss)
I0524 09:48:50.431046  5984 sgd_solver.cpp:106] Iteration 3100, lr = 0.0081667
I0524 09:48:55.333314  5984 solver.cpp:228] Iteration 3200, loss = 0.0298272
I0524 09:48:55.333314  5984 solver.cpp:244]     Train net output #0: loss = 0.0298269 (* 1 = 0.0298269 loss)
I0524 09:48:55.333314  5984 sgd_solver.cpp:106] Iteration 3200, lr = 0.00812025
I0524 09:49:00.254595  5984 solver.cpp:228] Iteration 3300, loss = 0.0462442
I0524 09:49:00.254595  5984 solver.cpp:244]     Train net output #0: loss = 0.0462439 (* 1 = 0.0462439 loss)
I0524 09:49:00.254595  5984 sgd_solver.cpp:106] Iteration 3300, lr = 0.00807442
I0524 09:49:05.172874  5984 solver.cpp:228] Iteration 3400, loss = 0.0122815
I0524 09:49:05.172874  5984 solver.cpp:244]     Train net output #0: loss = 0.0122812 (* 1 = 0.0122812 loss)
I0524 09:49:05.172874  5984 sgd_solver.cpp:106] Iteration 3400, lr = 0.00802918
I0524 09:49:10.120172  5984 solver.cpp:228] Iteration 3500, loss = 2.59839e-007
I0524 09:49:10.120172  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:49:10.120172  5984 sgd_solver.cpp:106] Iteration 3500, lr = 0.00798454
I0524 09:49:15.078478  5984 solver.cpp:228] Iteration 3600, loss = 0.0434709
I0524 09:49:15.078478  5984 solver.cpp:244]     Train net output #0: loss = 0.0434706 (* 1 = 0.0434706 loss)
I0524 09:49:15.078478  5984 sgd_solver.cpp:106] Iteration 3600, lr = 0.00794046
I0524 09:49:19.899693  5984 solver.cpp:228] Iteration 3700, loss = 0.0676636
I0524 09:49:19.899693  5984 solver.cpp:244]     Train net output #0: loss = 0.0676633 (* 1 = 0.0676633 loss)
I0524 09:49:19.899693  5984 sgd_solver.cpp:106] Iteration 3700, lr = 0.00789695
I0524 09:49:24.914036  5984 solver.cpp:228] Iteration 3800, loss = 0.0381228
I0524 09:49:24.914036  5984 solver.cpp:244]     Train net output #0: loss = 0.0381225 (* 1 = 0.0381225 loss)
I0524 09:49:24.914036  5984 sgd_solver.cpp:106] Iteration 3800, lr = 0.007854
I0524 09:49:29.889747  5984 solver.cpp:228] Iteration 3900, loss = 0.0374319
I0524 09:49:29.889747  5984 solver.cpp:244]     Train net output #0: loss = 0.0374316 (* 1 = 0.0374316 loss)
I0524 09:49:29.889747  5984 sgd_solver.cpp:106] Iteration 3900, lr = 0.00781158
I0524 09:49:34.844050  5984 solver.cpp:228] Iteration 4000, loss = 0.0324109
I0524 09:49:34.844050  5984 solver.cpp:244]     Train net output #0: loss = 0.0324106 (* 1 = 0.0324106 loss)
I0524 09:49:34.844050  5984 sgd_solver.cpp:106] Iteration 4000, lr = 0.00776969
I0524 09:49:39.756325  5984 solver.cpp:228] Iteration 4100, loss = 0.0538232
I0524 09:49:39.757326  5984 solver.cpp:244]     Train net output #0: loss = 0.0538229 (* 1 = 0.0538229 loss)
I0524 09:49:39.757326  5984 sgd_solver.cpp:106] Iteration 4100, lr = 0.00772833
I0524 09:49:44.665598  5984 solver.cpp:228] Iteration 4200, loss = 0.0164235
I0524 09:49:44.665598  5984 solver.cpp:244]     Train net output #0: loss = 0.0164233 (* 1 = 0.0164233 loss)
I0524 09:49:44.665598  5984 sgd_solver.cpp:106] Iteration 4200, lr = 0.00768748
I0524 09:49:49.571869  5984 solver.cpp:228] Iteration 4300, loss = 0.133821
I0524 09:49:49.571869  5984 solver.cpp:244]     Train net output #0: loss = 0.133821 (* 1 = 0.133821 loss)
I0524 09:49:49.571869  5984 sgd_solver.cpp:106] Iteration 4300, lr = 0.00764712
I0524 09:49:54.513164  5984 solver.cpp:228] Iteration 4400, loss = 0.040184
I0524 09:49:54.513164  5984 solver.cpp:244]     Train net output #0: loss = 0.0401838 (* 1 = 0.0401838 loss)
I0524 09:49:54.513164  5984 sgd_solver.cpp:106] Iteration 4400, lr = 0.00760726
I0524 09:49:59.414432  5984 solver.cpp:228] Iteration 4500, loss = 0.0128583
I0524 09:49:59.414432  5984 solver.cpp:244]     Train net output #0: loss = 0.0128581 (* 1 = 0.0128581 loss)
I0524 09:49:59.414432  5984 sgd_solver.cpp:106] Iteration 4500, lr = 0.00756788
I0524 09:50:04.284677  5984 solver.cpp:228] Iteration 4600, loss = 0.0230311
I0524 09:50:04.284677  5984 solver.cpp:244]     Train net output #0: loss = 0.0230309 (* 1 = 0.0230309 loss)
I0524 09:50:04.284677  5984 sgd_solver.cpp:106] Iteration 4600, lr = 0.00752897
I0524 09:50:09.171936  5984 solver.cpp:228] Iteration 4700, loss = 0.00293823
I0524 09:50:09.171936  5984 solver.cpp:244]     Train net output #0: loss = 0.00293798 (* 1 = 0.00293798 loss)
I0524 09:50:09.171936  5984 sgd_solver.cpp:106] Iteration 4700, lr = 0.00749052
I0524 09:50:14.091215  5984 solver.cpp:228] Iteration 4800, loss = 0.034692
I0524 09:50:14.091215  5984 solver.cpp:244]     Train net output #0: loss = 0.0346918 (* 1 = 0.0346918 loss)
I0524 09:50:14.091215  5984 sgd_solver.cpp:106] Iteration 4800, lr = 0.00745253
I0524 09:50:19.024504  5984 solver.cpp:228] Iteration 4900, loss = 2.75671e-007
I0524 09:50:19.024504  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:50:19.024504  5984 sgd_solver.cpp:106] Iteration 4900, lr = 0.00741498
I0524 09:50:23.873738  5984 solver.cpp:454] Snapshotting to binary proto file ../../../examples/mnist/lenet_iter_5000.caffemodel
I0524 09:50:23.882745  5984 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../../../examples/mnist/lenet_iter_5000.solverstate
I0524 09:50:23.935780  5984 solver.cpp:228] Iteration 5000, loss = 0.0282721
I0524 09:50:23.935780  5984 solver.cpp:244]     Train net output #0: loss = 0.0282719 (* 1 = 0.0282719 loss)
I0524 09:50:23.935780  5984 sgd_solver.cpp:106] Iteration 5000, lr = 0.00737788
I0524 09:50:28.840049  5984 solver.cpp:228] Iteration 5100, loss = 0.0296438
I0524 09:50:28.840049  5984 solver.cpp:244]     Train net output #0: loss = 0.0296435 (* 1 = 0.0296435 loss)
I0524 09:50:28.840049  5984 sgd_solver.cpp:106] Iteration 5100, lr = 0.0073412
I0524 09:50:33.773337  5984 solver.cpp:228] Iteration 5200, loss = 0.0132935
I0524 09:50:33.773337  5984 solver.cpp:244]     Train net output #0: loss = 0.0132932 (* 1 = 0.0132932 loss)
I0524 09:50:33.773337  5984 sgd_solver.cpp:106] Iteration 5200, lr = 0.00730495
I0524 09:50:38.695618  5984 solver.cpp:228] Iteration 5300, loss = 0.00651024
I0524 09:50:38.695618  5984 solver.cpp:244]     Train net output #0: loss = 0.00651 (* 1 = 0.00651 loss)
I0524 09:50:38.695618  5984 sgd_solver.cpp:106] Iteration 5300, lr = 0.00726911
I0524 09:50:43.584877  5984 solver.cpp:228] Iteration 5400, loss = 0.0217746
I0524 09:50:43.584877  5984 solver.cpp:244]     Train net output #0: loss = 0.0217744 (* 1 = 0.0217744 loss)
I0524 09:50:43.584877  5984 sgd_solver.cpp:106] Iteration 5400, lr = 0.00723368
I0524 09:50:48.531175  5984 solver.cpp:228] Iteration 5500, loss = 0.00933758
I0524 09:50:48.531175  5984 solver.cpp:244]     Train net output #0: loss = 0.0093373 (* 1 = 0.0093373 loss)
I0524 09:50:48.531175  5984 sgd_solver.cpp:106] Iteration 5500, lr = 0.00719865
I0524 09:50:53.423437  5984 solver.cpp:228] Iteration 5600, loss = 2.81259e-007
I0524 09:50:53.424438  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:50:53.424438  5984 sgd_solver.cpp:106] Iteration 5600, lr = 0.00716402
I0524 09:50:58.303691  5984 solver.cpp:228] Iteration 5700, loss = 2.75671e-007
I0524 09:50:58.303691  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:50:58.303691  5984 sgd_solver.cpp:106] Iteration 5700, lr = 0.00712977
I0524 09:51:03.236979  5984 solver.cpp:228] Iteration 5800, loss = 0.0406278
I0524 09:51:03.236979  5984 solver.cpp:244]     Train net output #0: loss = 0.0406275 (* 1 = 0.0406275 loss)
I0524 09:51:03.236979  5984 sgd_solver.cpp:106] Iteration 5800, lr = 0.0070959
I0524 09:51:08.123239  5984 solver.cpp:228] Iteration 5900, loss = 0.00555444
I0524 09:51:08.123239  5984 solver.cpp:244]     Train net output #0: loss = 0.00555415 (* 1 = 0.00555415 loss)
I0524 09:51:08.123239  5984 sgd_solver.cpp:106] Iteration 5900, lr = 0.0070624
I0524 09:51:13.021502  5984 solver.cpp:228] Iteration 6000, loss = 0.00361917
I0524 09:51:13.021502  5984 solver.cpp:244]     Train net output #0: loss = 0.00361886 (* 1 = 0.00361886 loss)
I0524 09:51:13.021502  5984 sgd_solver.cpp:106] Iteration 6000, lr = 0.00702927
I0524 09:51:17.928774  5984 solver.cpp:228] Iteration 6100, loss = 3.05474e-007
I0524 09:51:17.929775  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:51:17.929775  5984 sgd_solver.cpp:106] Iteration 6100, lr = 0.0069965
I0524 09:51:23.105371  5984 solver.cpp:228] Iteration 6200, loss = 0.00903431
I0524 09:51:23.105371  5984 solver.cpp:244]     Train net output #0: loss = 0.00903399 (* 1 = 0.00903399 loss)
I0524 09:51:23.105371  5984 sgd_solver.cpp:106] Iteration 6200, lr = 0.00696408
I0524 09:51:28.019645  5984 solver.cpp:228] Iteration 6300, loss = 3.25963e-007
I0524 09:51:28.019645  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:51:28.019645  5984 sgd_solver.cpp:106] Iteration 6300, lr = 0.00693201
I0524 09:51:32.945930  5984 solver.cpp:228] Iteration 6400, loss = 0.019312
I0524 09:51:32.945930  5984 solver.cpp:244]     Train net output #0: loss = 0.0193116 (* 1 = 0.0193116 loss)
I0524 09:51:32.945930  5984 sgd_solver.cpp:106] Iteration 6400, lr = 0.00690029
I0524 09:51:37.865209  5984 solver.cpp:228] Iteration 6500, loss = 0.0366637
I0524 09:51:37.865209  5984 solver.cpp:244]     Train net output #0: loss = 0.0366634 (* 1 = 0.0366634 loss)
I0524 09:51:37.865209  5984 sgd_solver.cpp:106] Iteration 6500, lr = 0.0068689
I0524 09:51:42.733455  5984 solver.cpp:228] Iteration 6600, loss = 0.0484379
I0524 09:51:42.734455  5984 solver.cpp:244]     Train net output #0: loss = 0.0484376 (* 1 = 0.0484376 loss)
I0524 09:51:42.734455  5984 sgd_solver.cpp:106] Iteration 6600, lr = 0.00683784
I0524 09:51:47.593695  5984 solver.cpp:228] Iteration 6700, loss = 0.0218327
I0524 09:51:47.593695  5984 solver.cpp:244]     Train net output #0: loss = 0.0218324 (* 1 = 0.0218324 loss)
I0524 09:51:47.593695  5984 sgd_solver.cpp:106] Iteration 6700, lr = 0.00680711
I0524 09:51:52.501967  5984 solver.cpp:228] Iteration 6800, loss = 0.00517046
I0524 09:51:52.501967  5984 solver.cpp:244]     Train net output #0: loss = 0.00517015 (* 1 = 0.00517015 loss)
I0524 09:51:52.501967  5984 sgd_solver.cpp:106] Iteration 6800, lr = 0.0067767
I0524 09:51:57.399232  5984 solver.cpp:228] Iteration 6900, loss = 0.00909146
I0524 09:51:57.399232  5984 solver.cpp:244]     Train net output #0: loss = 0.00909114 (* 1 = 0.00909114 loss)
I0524 09:51:57.399232  5984 sgd_solver.cpp:106] Iteration 6900, lr = 0.0067466
I0524 09:52:02.293495  5984 solver.cpp:228] Iteration 7000, loss = 0.00442145
I0524 09:52:02.293495  5984 solver.cpp:244]     Train net output #0: loss = 0.00442113 (* 1 = 0.00442113 loss)
I0524 09:52:02.293495  5984 sgd_solver.cpp:106] Iteration 7000, lr = 0.00671681
I0524 09:52:07.225782  5984 solver.cpp:228] Iteration 7100, loss = 0.0645045
I0524 09:52:07.225782  5984 solver.cpp:244]     Train net output #0: loss = 0.0645042 (* 1 = 0.0645042 loss)
I0524 09:52:07.226783  5984 sgd_solver.cpp:106] Iteration 7100, lr = 0.00668733
I0524 09:52:12.154068  5984 solver.cpp:228] Iteration 7200, loss = 0.00775418
I0524 09:52:12.154068  5984 solver.cpp:244]     Train net output #0: loss = 0.00775385 (* 1 = 0.00775385 loss)
I0524 09:52:12.154068  5984 sgd_solver.cpp:106] Iteration 7200, lr = 0.00665815
I0524 09:52:17.039808  5984 solver.cpp:228] Iteration 7300, loss = 0.0548216
I0524 09:52:17.039808  5984 solver.cpp:244]     Train net output #0: loss = 0.0548212 (* 1 = 0.0548212 loss)
I0524 09:52:17.039808  5984 sgd_solver.cpp:106] Iteration 7300, lr = 0.00662927
I0524 09:52:21.944077  5984 solver.cpp:228] Iteration 7400, loss = 0.0110742
I0524 09:52:21.944077  5984 solver.cpp:244]     Train net output #0: loss = 0.0110738 (* 1 = 0.0110738 loss)
I0524 09:52:21.944077  5984 sgd_solver.cpp:106] Iteration 7400, lr = 0.00660067
I0524 09:52:26.870362  5984 solver.cpp:228] Iteration 7500, loss = 0.0156021
I0524 09:52:26.870362  5984 solver.cpp:244]     Train net output #0: loss = 0.0156018 (* 1 = 0.0156018 loss)
I0524 09:52:26.870362  5984 sgd_solver.cpp:106] Iteration 7500, lr = 0.00657236
I0524 09:52:31.778633  5984 solver.cpp:228] Iteration 7600, loss = 0.0326077
I0524 09:52:31.778633  5984 solver.cpp:244]     Train net output #0: loss = 0.0326073 (* 1 = 0.0326073 loss)
I0524 09:52:31.778633  5984 sgd_solver.cpp:106] Iteration 7600, lr = 0.00654433
I0524 09:52:36.726933  5984 solver.cpp:228] Iteration 7700, loss = 0.0387646
I0524 09:52:36.726933  5984 solver.cpp:244]     Train net output #0: loss = 0.0387643 (* 1 = 0.0387643 loss)
I0524 09:52:36.726933  5984 sgd_solver.cpp:106] Iteration 7700, lr = 0.00651658
I0524 09:52:41.631202  5984 solver.cpp:228] Iteration 7800, loss = 0.0190344
I0524 09:52:41.631202  5984 solver.cpp:244]     Train net output #0: loss = 0.0190341 (* 1 = 0.0190341 loss)
I0524 09:52:41.631202  5984 sgd_solver.cpp:106] Iteration 7800, lr = 0.00648911
I0524 09:52:46.548480  5984 solver.cpp:228] Iteration 7900, loss = 0.00996187
I0524 09:52:46.548480  5984 solver.cpp:244]     Train net output #0: loss = 0.00996152 (* 1 = 0.00996152 loss)
I0524 09:52:46.548480  5984 sgd_solver.cpp:106] Iteration 7900, lr = 0.0064619
I0524 09:52:51.449748  5984 solver.cpp:228] Iteration 8000, loss = 0.00705722
I0524 09:52:51.449748  5984 solver.cpp:244]     Train net output #0: loss = 0.00705688 (* 1 = 0.00705688 loss)
I0524 09:52:51.449748  5984 sgd_solver.cpp:106] Iteration 8000, lr = 0.00643496
I0524 09:52:56.396046  5984 solver.cpp:228] Iteration 8100, loss = 0.0361494
I0524 09:52:56.396046  5984 solver.cpp:244]     Train net output #0: loss = 0.0361491 (* 1 = 0.0361491 loss)
I0524 09:52:56.396046  5984 sgd_solver.cpp:106] Iteration 8100, lr = 0.00640827
I0524 09:53:01.304762  5984 solver.cpp:228] Iteration 8200, loss = 0.0159007
I0524 09:53:01.304762  5984 solver.cpp:244]     Train net output #0: loss = 0.0159004 (* 1 = 0.0159004 loss)
I0524 09:53:01.304762  5984 sgd_solver.cpp:106] Iteration 8200, lr = 0.00638185
I0524 09:53:06.207031  5984 solver.cpp:228] Iteration 8300, loss = 0.0957445
I0524 09:53:06.207031  5984 solver.cpp:244]     Train net output #0: loss = 0.0957441 (* 1 = 0.0957441 loss)
I0524 09:53:06.207031  5984 sgd_solver.cpp:106] Iteration 8300, lr = 0.00635568
I0524 09:53:11.124308  5984 solver.cpp:228] Iteration 8400, loss = 0.0445185
I0524 09:53:11.124308  5984 solver.cpp:244]     Train net output #0: loss = 0.0445181 (* 1 = 0.0445181 loss)
I0524 09:53:11.124308  5984 sgd_solver.cpp:106] Iteration 8400, lr = 0.00632975
I0524 09:53:15.969538  5984 solver.cpp:228] Iteration 8500, loss = 3.68804e-007
I0524 09:53:15.969538  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:53:15.969538  5984 sgd_solver.cpp:106] Iteration 8500, lr = 0.00630407
I0524 09:53:20.889819  5984 solver.cpp:228] Iteration 8600, loss = 3.66941e-007
I0524 09:53:20.889819  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:53:20.889819  5984 sgd_solver.cpp:106] Iteration 8600, lr = 0.00627864
I0524 09:53:25.819104  5984 solver.cpp:228] Iteration 8700, loss = 0.00192407
I0524 09:53:25.819104  5984 solver.cpp:244]     Train net output #0: loss = 0.0019237 (* 1 = 0.0019237 loss)
I0524 09:53:25.819104  5984 sgd_solver.cpp:106] Iteration 8700, lr = 0.00625344
I0524 09:53:30.756397  5984 solver.cpp:228] Iteration 8800, loss = 0.00238653
I0524 09:53:30.756397  5984 solver.cpp:244]     Train net output #0: loss = 0.00238615 (* 1 = 0.00238615 loss)
I0524 09:53:30.756397  5984 sgd_solver.cpp:106] Iteration 8800, lr = 0.00622847
I0524 09:53:35.702694  5984 solver.cpp:228] Iteration 8900, loss = 3.61353e-007
I0524 09:53:35.702694  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:53:35.702694  5984 sgd_solver.cpp:106] Iteration 8900, lr = 0.00620374
I0524 09:53:40.647991  5984 solver.cpp:228] Iteration 9000, loss = 0.0127773
I0524 09:53:40.647991  5984 solver.cpp:244]     Train net output #0: loss = 0.0127769 (* 1 = 0.0127769 loss)
I0524 09:53:40.647991  5984 sgd_solver.cpp:106] Iteration 9000, lr = 0.00617924
I0524 09:53:45.600292  5984 solver.cpp:228] Iteration 9100, loss = 0.00561156
I0524 09:53:45.601294  5984 solver.cpp:244]     Train net output #0: loss = 0.0056112 (* 1 = 0.0056112 loss)
I0524 09:53:45.601294  5984 sgd_solver.cpp:106] Iteration 9100, lr = 0.00615496
I0524 09:53:50.521291  5984 solver.cpp:228] Iteration 9200, loss = 0.0106715
I0524 09:53:50.521291  5984 solver.cpp:244]     Train net output #0: loss = 0.0106711 (* 1 = 0.0106711 loss)
I0524 09:53:50.521291  5984 sgd_solver.cpp:106] Iteration 9200, lr = 0.0061309
I0524 09:53:55.484598  5984 solver.cpp:228] Iteration 9300, loss = 0.00607011
I0524 09:53:55.484598  5984 solver.cpp:244]     Train net output #0: loss = 0.00606975 (* 1 = 0.00606975 loss)
I0524 09:53:55.484598  5984 sgd_solver.cpp:106] Iteration 9300, lr = 0.00610706
I0524 09:54:00.397874  5984 solver.cpp:228] Iteration 9400, loss = 0.0879247
I0524 09:54:00.397874  5984 solver.cpp:244]     Train net output #0: loss = 0.0879244 (* 1 = 0.0879244 loss)
I0524 09:54:00.397874  5984 sgd_solver.cpp:106] Iteration 9400, lr = 0.00608343
I0524 09:54:05.270123  5984 solver.cpp:228] Iteration 9500, loss = 0.00203278
I0524 09:54:05.270123  5984 solver.cpp:244]     Train net output #0: loss = 0.00203241 (* 1 = 0.00203241 loss)
I0524 09:54:05.270123  5984 sgd_solver.cpp:106] Iteration 9500, lr = 0.00606002
I0524 09:54:10.235433  5984 solver.cpp:228] Iteration 9600, loss = 3.68804e-007
I0524 09:54:10.235433  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:54:10.235433  5984 sgd_solver.cpp:106] Iteration 9600, lr = 0.00603682
I0524 09:54:15.209749  5984 solver.cpp:228] Iteration 9700, loss = 3.72529e-007
I0524 09:54:15.209749  5984 solver.cpp:244]     Train net output #0: loss = 0 (* 1 = 0 loss)
I0524 09:54:15.209749  5984 sgd_solver.cpp:106] Iteration 9700, lr = 0.00601382
I0524 09:54:20.146040  5984 solver.cpp:228] Iteration 9800, loss = 0.0465109
I0524 09:54:20.146040  5984 solver.cpp:244]     Train net output #0: loss = 0.0465105 (* 1 = 0.0465105 loss)
I0524 09:54:20.146040  5984 sgd_solver.cpp:106] Iteration 9800, lr = 0.00599102
I0524 09:54:25.119356  5984 solver.cpp:228] Iteration 9900, loss = 0.00174376
I0524 09:54:25.119356  5984 solver.cpp:244]     Train net output #0: loss = 0.00174339 (* 1 = 0.00174339 loss)
I0524 09:54:25.119356  5984 sgd_solver.cpp:106] Iteration 9900, lr = 0.00596843
I0524 09:54:30.014619  5984 solver.cpp:454] Snapshotting to binary proto file ../../../examples/mnist/lenet_iter_10000.caffemodel
I0524 09:54:30.023625  5984 sgd_solver.cpp:273] Snapshotting solver state to binary proto file ../../../examples/mnist/lenet_iter_10000.solverstate
I0524 09:54:30.050645  5984 solver.cpp:317] Iteration 10000, loss = 3.7346e-007
I0524 09:54:30.050645  5984 solver.cpp:322] Optimization Done.
I0524 09:54:30.050645  5984 caffe.cpp:255] Optimization Done.
